{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16110011_AMit_Assignment_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii3PB9-tSO8T",
        "colab_type": "text"
      },
      "source": [
        "NLP Assignment-3 : Sentiment Analysis- Amit Kumar Singh Yadav| 16110011"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9aVW3YKnYdQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "42b5f7f6-a1a1-4693-fcf7-f4b17fe288c0"
      },
      "source": [
        "\n",
        "\n",
        "#ALL HEADER FILES INCLUDED\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import SpatialDropout1D\n",
        "from keras.models import Model\n",
        "from keras.layers import Input,Flatten, Dense, Embedding, RNN, Conv1D, BatchNormalization, MaxPooling1D, Activation, Dropout, concatenate, Lambda\n",
        "from keras import optimizers\n",
        "from keras.layers.convolutional import Convolution1D\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Lambda\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Lambda\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import optimizers\n",
        "import pickle as p\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "from bs4 import BeautifulSoup  \n",
        "import re\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "datapath = '/content/gdrive/My Drive/Colab Notebooks/Assignment_3/'\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgzRbxoiSdwh",
        "colab_type": "text"
      },
      "source": [
        "Train and Text File Reading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCgHxayInael",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(datapath+\"train.txt\",\"r\") as traintext:\n",
        "  train_file=traintext.read()\n",
        "\n",
        "with open(datapath+\"test.txt\",\"r\") as testtext:\n",
        "  test_file=testtext.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjD65i_1SkaZ",
        "colab_type": "text"
      },
      "source": [
        "Defination for PreProcessing Data and Emoji \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjgTH5danhjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Emoji2Vec USED EMOJIS - FROM \n",
        "remove_en=stopwords.words('english')\n",
        "exception=['not','never', 'no','ever','very','nothing','really','extremely']\n",
        "emodict = {0:'amusement', 1:'satisfaction', 2:'optimism', 3:'pride in achievement', 4:'contentment',\n",
        "           5:'anger', 6:'fear', 7:'disgust', 8:'sadness', 9:'contempt'}\n",
        "#emotion_label = {\n",
        "#\t\t\"fear\" : ['😳', '😰', '😨', '😬'],\n",
        "#\t\t\"anger\" : ['😱', '😡', '😤', '😒', '😑', '😠'],\n",
        "#\t\t\"disgust\" :['😭', '😩', '🤦', '😯', '🤢', '😖'],\n",
        "#\t\t\"sadness\" :['😫', '😭', '😞'] ,\n",
        "#\t\t\"contempt\" :['😔', '💔', '😏'],\n",
        "#\t\t\"amusement\" :['😲'],\n",
        "#   \"pride in achievement\" :['👌', '👏', '👍'],\n",
        "#    \"satisfaction\" :['😊', '🙏', '😔', '😎'],\n",
        "#    \"optimism\" :['💪', '😎', '🛐'],\n",
        "#    \"contentment\" :['😇', '😘', '😂', '😁', '💃'],\n",
        "#    \"none\": ['none']  \n",
        "#        }\n",
        "\n",
        "emoji_label={\n",
        "    \"negative\":['😳', '😰', '😨', '😬','😱', '😡', '😤', '😒', '😑', '😠','😭', '😩', '🤦', '😯', '🤢', '😖', '😫', '😭', '😞','😔', '💔', '😏' ],# fear+anger+disgust+sadness+contempt\n",
        "    \"neutral\":['😊', '🙏'],#satisfaction\n",
        "    \"positive\":['😇', '😘', '😂', '😁', '💃','💪', '😎', '🛐','👌', '👏', '👍','😲']#optimmism + contentment\n",
        "}\n",
        "emoji=['😳', '😰', '😨', '😬','😱', '😡', '😤', '😒', '😑', '😠','😭', '😩', '🤦', '😯', '🤢', '😖', '😫', '😭', '😞','😔', '💔', '😏', '😊', '🙏','😇', '😘', '😂', '😁', '💃','💪',\n",
        "       '😎', '🛐','👌', '👏', '👍','😲']\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51p-FIL_SuSW",
        "colab_type": "text"
      },
      "source": [
        "Importing Data and Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVzxwWdpnllF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd5f8de0-ca64-4530-a772-dfa0708083bb"
      },
      "source": [
        "train_id, train_text, train_label, train_c_h, train_c_e, train_c_o=[],[],[],[],[],[]\n",
        "\n",
        "for tweet in train_file.split('\\n\\n'):\n",
        "  lines=tweet.split('\\n')\n",
        "  try:\n",
        "    train_label.append(lines[0].split()[2])\n",
        "    train_id.append(lines[0].split()[1])\n",
        "  except IndexError:\n",
        "    del train_id[-1]\n",
        "    continue\n",
        "  temp_c,temp_c_h,temp_c_e,temp_c_o=[],[],[],[]\n",
        "  for line in lines[1:]:\n",
        "    words=line.split('\\t')\n",
        "    words[0]=words[0].lower()\n",
        "    if(words[1]!='0'):\n",
        "      words[0]=re.sub('[\\W_]+','',words[0])\n",
        "    if words[1]=='Eng' and words[0] in remove_en and words[0] not in exception:\n",
        "      continue\n",
        "    if 'http' in words[0]:\n",
        "      continue\n",
        "    temp_c.append(words[0])\n",
        "    if words[1]== 'Eng':\n",
        "      temp_c_e.append(words[0])\n",
        "    if words[1]== 'Hin':\n",
        "      temp_c_h.append(words[0])\n",
        "    elif words[1]== 'O':\n",
        "      if(words[0] in emoji):\n",
        "        temp_c_o.append(words[0])\n",
        "      \n",
        "  if temp_c==[]:\n",
        "    continue\n",
        "  train_text.append(temp_c)\n",
        "  train_c_h.append(temp_c_h)\n",
        "  train_c_e.append(temp_c_e)\n",
        "  train_c_o.append(temp_c_o)\n",
        "\n",
        "\n",
        "print(len(train_text))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpSHW_zzSzXH",
        "colab_type": "text"
      },
      "source": [
        "Pre-Processing and Importing Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFTpcA4-nneK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc0d6dd7-2cc6-43fc-be35-71785dc7ce23"
      },
      "source": [
        "test_id, test_text, test_label, test_c_h, test_c_e, test_c_o=[],[],[],[],[],[]\n",
        "\n",
        "for tweet in test_file.split('\\n\\n'):\n",
        "  lines=tweet.split('\\n')\n",
        "  try:\n",
        "    test_label.append(lines[0].split()[2])\n",
        "    test_id.append(lines[0].split()[1])\n",
        "  except IndexError:\n",
        "    del test_id[-1]\n",
        "    continue\n",
        "  temp_c,temp_c_h,temp_c_e,temp_c_o=[],[],[],[]\n",
        "  for line in lines[1:]:\n",
        "    words=line.split('\\t')\n",
        "    words[0]=words[0].lower()\n",
        "    if(words[1]!='0'):\n",
        "      #words[0]=re.sub('[\\W_]+','',words[0])\n",
        "      words[0]=words[0]\n",
        "    if words[1]=='Eng' and words[0] in remove_en and words[0] not in exception:\n",
        "      continue\n",
        "    if 'http' in words[0]:\n",
        "      continue\n",
        "    temp_c.append(words[0])\n",
        "    if words[1]== 'Eng':\n",
        "      temp_c_e.append(words[0])\n",
        "    if words[1]== 'Hin':\n",
        "      temp_c_h.append(words[0])\n",
        "    elif words[1]== 'O':\n",
        "      if(words[0] in emoji):\n",
        "        temp_c_o.append(words[0])\n",
        "  if temp_c==[]:\n",
        "    continue\n",
        "  test_text.append(temp_c)\n",
        "  test_c_h.append(temp_c_h)\n",
        "  test_c_e.append(temp_c_e)\n",
        "  test_c_o.append(temp_c_o)\n",
        "\n",
        "\n",
        "print(len(test_text))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdshk0NvS5HP",
        "colab_type": "text"
      },
      "source": [
        "Compiling all Train and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSdy696snr0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cf4e3fe-11e5-4564-f962-d7dc6556ac86"
      },
      "source": [
        "train_tweet= [' '.join(i) for i in train_text]\n",
        "test_tweet= [' '.join(i) for i in test_text]\n",
        "\n",
        "train_tweet_dict, test_tweet_dict={},{}\n",
        "\n",
        "train_tweet_dict['hin']= [' '.join(i) for i in train_c_h]\n",
        "train_tweet_dict['eng']= [' '.join(i) for i in train_c_e]\n",
        "\n",
        "test_tweet_dict['hin']= [' '.join(i) for i in test_c_h]\n",
        "test_tweet_dict['eng']= [' '.join(i) for i in test_c_e]\n",
        "\n",
        "train_tweet_dict['o']= [' '.join(i) for i in train_c_o]\n",
        "test_tweet_dict['o']= [' '.join(i) for i in test_c_o]\n",
        "\n",
        "np.unique(train_label)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative', 'neutral', 'positive'], dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzYFjQBzS9K4",
        "colab_type": "text"
      },
      "source": [
        "Fitting Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYukpgdOogbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 20000\n",
        "tokenizer1 = Tokenizer(num_words=max_features)\n",
        "tokenizer1.fit_on_texts(train_tweet)\n",
        "max_len = 300\n",
        "num_classes = 3\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpKJYHv-TCTy",
        "colab_type": "text"
      },
      "source": [
        "Making Embeddings Dictionary for Negative, Positive and Neutral Sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coJNLj3xnx7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import *\n",
        "tweet_ = {}\n",
        "for label in ['negative', 'neutral', 'positive']:\n",
        "  tweet_[label] = {}\n",
        "  for key in ['eng', 'hin', 'o']:\n",
        "    tweet_[label][key] = []\n",
        "\n",
        "# negative_tweet_e, positive_tweet_e, neutral_tweet_e=[],[],[]\n",
        "# negative_tweet_h, positive_tweet_h, neutral_tweet_h=[],[],[]\n",
        "# negative_tweet_o, positive_tweet_o, neutral_tweet_o=[],[],[]\n",
        "train_tweet_embeddings=[] #eng+hindi+emoji\n",
        "\n",
        "for i in range(len(train_label)):\n",
        "  temp=[]\n",
        "  for key in ['eng', 'hin', 'o']:\n",
        "    words = train_tweet_dict[key][i].split(\" \")\n",
        "    seq=tokenizer1.texts_to_sequences(words)\n",
        "    vector_list=sequence.pad_sequences(seq, maxlen=max_len)\n",
        "    #vector_list = [model[word] for word in words if word in model.vocab]\n",
        "    j = 0\n",
        "    while j < len(vector_list):\n",
        "      if sum(np.isnan(vector_list[j]))>0:\n",
        "        del vector_list[j]\n",
        "      else:\n",
        "        j += 1\n",
        "    avg_vector = np.nanmean(vector_list,axis=0)\n",
        "    if sum(np.isnan(avg_vector)) == 0:\n",
        "      tweet_[train_label[i]][key].append(avg_vector)\n",
        "    temp.append(avg_vector)\n",
        "  temp = np.average(temp,axis=0)\n",
        "  train_tweet_embeddings.append(temp)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4KGkUPITRn8",
        "colab_type": "text"
      },
      "source": [
        "Test Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTxFf_xin0uN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_tweet_embeddings=[]\n",
        "for i in range(len(test_tweet)):\n",
        "  words = test_tweet[i].split(\" \")\n",
        "  seq=tokenizer1.texts_to_sequences(words)\n",
        "  vector_list=sequence.pad_sequences(seq, maxlen=max_len)\n",
        "  avg_vector = np.average(vector_list,axis=0)\n",
        "  test_tweet_embeddings.append(avg_vector)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1fP4ATYTIZn",
        "colab_type": "text"
      },
      "source": [
        "Weighted Averaging embedding for each type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpEfiicDn3iY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "b1067234-bec0-4f65-9002-e2e8bdf6d7f9"
      },
      "source": [
        "avg_={}\n",
        "for label in ['negative','neutral','positive']:\n",
        "  avg_[label]={}\n",
        "  for key in ['eng','hin','o']:\n",
        "    avg_[label][key]=np.nanmean(tweet_[label][key],axis=0)\n",
        "    print(sum(avg_[label][key]))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2420.1217563024325\n",
            "1574.2338323387705\n",
            "0.0\n",
            "2513.426942012764\n",
            "1745.986567814108\n",
            "0.0\n",
            "2246.894273742185\n",
            "1710.3447755149716\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RRR-qqYTWJu",
        "colab_type": "text"
      },
      "source": [
        "Creating Similarity Feature for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q58MIsAHn6Na",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "similarity=[]\n",
        "for i in range(len(train_tweet_embeddings)):\n",
        "  temp=[]\n",
        "  for label in ['negative','neutral','positive']:\n",
        "    for key in ['eng','hin']:\n",
        "      distance = scipy.spatial.distance.cosine(avg_[label][key],train_tweet_embeddings[i])\n",
        "      temp.append(distance)\n",
        "  similarity.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pTu3yi8Tcx0",
        "colab_type": "text"
      },
      "source": [
        "Creating Similarity Feature for Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwIGHEXAn8cH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "similarity_test=[]\n",
        "for i in range(len(test_tweet_embeddings)):\n",
        "  temp=[]\n",
        "  for label in ['negative','neutral','positive']:\n",
        "    for key in ['eng','hin']:\n",
        "      distance = scipy.spatial.distance.cosine(avg_[label][key],test_tweet_embeddings[i])\n",
        "      temp.append(distance)\n",
        "  similarity_test.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOnnJvmZn-_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c9c590f-7129-468e-9fac-182dc57eba2a"
      },
      "source": [
        "similarity=np.array(similarity)\n",
        "similarity_test=np.array(similarity_test)\n",
        "\n",
        "similarity.shape, similarity_test.shape\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((15131, 6), (1869, 6))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft6_1erWThZK",
        "colab_type": "text"
      },
      "source": [
        "Creting Y Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1XEEk4xpzBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_v = {'negative':0, 'neutral':1, 'positive':2}\n",
        "y_train = np.array([label_v[i] for i in train_label])\n",
        "y_test = np.array([label_v[i] for i in test_label])\n",
        "Y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N6P6rqsTlAr",
        "colab_type": "text"
      },
      "source": [
        "Using Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zKL9RKDoDrW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "7679e293-8b9a-4a80-f34b-444a45abe07e"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model=DecisionTreeClassifier()\n",
        "model.fit(similarity,Y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
              "                       max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort=False,\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk1rD0wcTpDP",
        "colab_type": "text"
      },
      "source": [
        "Accuracy for Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcf21MKAp8sG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "510fce81-25c0-4403-d468-308f101e121c"
      },
      "source": [
        "preds=model.predict(similarity_test)\n",
        "preds=np.argmax(preds,axis=1)\n",
        "np.sum(preds==y_test)/len(y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28517924023542"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms6uX1TiTs1t",
        "colab_type": "text"
      },
      "source": [
        "TOkenizing Sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzcgCxNkqdzs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "463b427e-eeed-4aaa-c4c0-51747a7e92c6"
      },
      "source": [
        "sequences_train = tokenizer1.texts_to_sequences(train_tweet)\n",
        "sequences_test = tokenizer1.texts_to_sequences(test_tweet)\n",
        "X_train = sequence.pad_sequences(sequences_train, maxlen=max_len)\n",
        "X_test = sequence.pad_sequences(sequences_test, maxlen=max_len)\n",
        "X_train_1=np.hstack((X_train, similarity))\n",
        "X_test_1=np.hstack((X_test, similarity_test))\n",
        "print('X_train shape:', X_train_1.shape)\n",
        "print('X_test shape:', X_test_1.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (15131, 306)\n",
            "X_test shape: (1869, 306)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQsN9bFrTytw",
        "colab_type": "text"
      },
      "source": [
        "Training Normal Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POoJSPL6rAvW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "3c443902-0756-4bec-a962-b2e2ce01d3e3"
      },
      "source": [
        "nb_filter = 300\n",
        "filter_length = 3\n",
        "hidden_dims = 300 # 250\n",
        "nb_epoch = 2\n",
        "\n",
        "\n",
        "neural = Sequential()\n",
        "neural.add(Dense(306))\n",
        "neural.add(Dropout(0.2))\n",
        "from keras import optimizers\n",
        "def max_1d(X):\n",
        "    return K.max(X, axis=1)\n",
        "\n",
        "neural.add(Dense(hidden_dims))\n",
        "neural.add(Dropout(0.2))\n",
        "neural.add(Activation('relu'))\n",
        "neural.add(Dense(num_classes))\n",
        "neural.add(Activation('sigmoid'))\n",
        "adam = optimizers.Adam(lr=0.001, decay=1e-6)\n",
        "neural.compile(loss='categorical_crossentropy',\n",
        "             optimizer=adam,\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqCV6o1RT3hC",
        "colab_type": "text"
      },
      "source": [
        "Fitting on Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2OALo1LrQ42",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "5b6de082-d04a-41de-8471-1cb17a8da4ec"
      },
      "source": [
        "neural.fit(X_train_1, Y_train, epochs = 4)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "15131/15131 [==============================] - 3s 169us/step - loss: nan - acc: 0.2947\n",
            "Epoch 2/4\n",
            "15131/15131 [==============================] - 3s 170us/step - loss: nan - acc: 0.2947\n",
            "Epoch 3/4\n",
            "15131/15131 [==============================] - 3s 170us/step - loss: nan - acc: 0.2947\n",
            "Epoch 4/4\n",
            "15131/15131 [==============================] - 3s 172us/step - loss: nan - acc: 0.2947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda7ad1bc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1DalokNT7Cl",
        "colab_type": "text"
      },
      "source": [
        "Accuracy of Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FkJ_-3ArmcE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7d24173-316d-4e82-9f14-4ebe820553ed"
      },
      "source": [
        "pred = neural.predict_classes(X_test_1, verbose=0)\n",
        "np.sum(pred==y_test)/len(y_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28517924023542"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwPnkSfCr0NS",
        "colab_type": "text"
      },
      "source": [
        "Using CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4WoCrDNr1DV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "aebafca3-05c5-47f6-d2e8-5a499e628cee"
      },
      "source": [
        "from keras import optimizers\n",
        "def max_1d(X):\n",
        "    return K.max(X, axis=1)\n",
        "\n",
        "\n",
        "nb_filter = 300\n",
        "filter_length = 3\n",
        "hidden_dims = 300 # 250\n",
        "nb_epoch = 2\n",
        "\n",
        "\n",
        "CNN = Sequential()\n",
        "CNN.add(Embedding(max_features, 400))\n",
        "CNN.add(SpatialDropout1D(0.2))\n",
        "CNN.add(Convolution1D(nb_filter=nb_filter,\n",
        "                      filter_length=filter_length,\n",
        "                      border_mode='valid',\n",
        "                      activation='tanh',\n",
        "                      subsample_length=1))\n",
        "CNN.add(Lambda(max_1d, output_shape=(nb_filter,)))\n",
        "CNN.add(Dense(hidden_dims))\n",
        "CNN.add(Dropout(0.2))\n",
        "CNN.add(Activation('relu'))\n",
        "CNN.add(Dense(num_classes))\n",
        "CNN.add(Activation('sigmoid'))\n",
        "adam = optimizers.Adam(lr=0.001, decay=1e-6)\n",
        "CNN.compile(loss='categorical_crossentropy',\n",
        "             optimizer=adam,\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"tanh\", filters=300, kernel_size=3, strides=1, padding=\"valid\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJP0L2UXsu_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "cc679885-49ed-4f5e-eedf-78866574cb3e"
      },
      "source": [
        "CNN.fit(X_train_1, Y_train, epochs = 2)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "15131/15131 [==============================] - 209s 14ms/step - loss: 0.8885 - acc: 0.5667\n",
            "Epoch 2/2\n",
            "15131/15131 [==============================] - 217s 14ms/step - loss: 0.6217 - acc: 0.7395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda79f00588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-4xiDCvUDIO",
        "colab_type": "text"
      },
      "source": [
        "Accuracy for 2 Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzYA9b0JtKWv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3a5ffc7-7ebc-4691-8106-4495222ee8f2"
      },
      "source": [
        "predsc1 = CNN.predict_classes(X_test_1, verbose=0)\n",
        "np.sum(predsc1==y_test)/len(y_test)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5575173889780631"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhD41TDzvE3g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "aa142c21-3055-4197-a0a7-f2f3b2c46f30"
      },
      "source": [
        "from keras import optimizers\n",
        "def max_1d(X):\n",
        "    return K.max(X, axis=1)\n",
        "\n",
        "\n",
        "nb_filter = 300\n",
        "filter_length = 3\n",
        "hidden_dims = 300 # 250\n",
        "nb_epoch = 2\n",
        "\n",
        "\n",
        "CNN2 = Sequential()\n",
        "CNN2.add(Embedding(max_features, 400))\n",
        "CNN2.add(SpatialDropout1D(0.2))\n",
        "CNN2.add(Convolution1D(nb_filter=nb_filter,\n",
        "                      filter_length=filter_length,\n",
        "                      border_mode='valid',\n",
        "                      activation='tanh',\n",
        "                      subsample_length=1))\n",
        "CNN2.add(Lambda(max_1d, output_shape=(nb_filter,)))\n",
        "CNN2.add(Dense(hidden_dims))\n",
        "CNN2.add(Dropout(0.2))\n",
        "CNN2.add(Activation('relu'))\n",
        "CNN2.add(Dense(num_classes))\n",
        "CNN2.add(Activation('sigmoid'))\n",
        "adam = optimizers.Adam(lr=0.001, decay=1e-6)\n",
        "CNN2.compile(loss='categorical_crossentropy',\n",
        "             optimizer=adam,\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"tanh\", filters=300, kernel_size=3, strides=1, padding=\"valid\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V-wBM4ovIkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from copy import deepcopy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKhgLMt3vUya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "orig = deepcopy(CNN2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggjVnLbyvNeS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "4fb00c6c-ca36-477a-db6e-43885a83d79a"
      },
      "source": [
        "CNN2.fit(X_train_1, Y_train, epochs = 1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "15131/15131 [==============================] - 214s 14ms/step - loss: 0.8873 - acc: 0.5665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda7cac5400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpGmuxVYUIHB",
        "colab_type": "text"
      },
      "source": [
        "Accuracy of CNN for 1 Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aTr5IHdvaPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd9477c5-58d9-4173-c807-1216cf364520"
      },
      "source": [
        "predsc2 = CNN2.predict_classes(X_test_1, verbose=0)\n",
        "np.sum(predsc2==y_test)/len(y_test)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5708935259497058"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XpGkqF8wdCM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c08fc42-b6c1-495d-b8f8-5facc15a926f"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as p_recall_f\n",
        "p_recall_f(y_test, predsc2, average='micro')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5708935259497058, 0.5708935259497058, 0.5708935259497058, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6a4uO05wjTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aec5d8d8-b325-43ff-ed2e-676754782c1a"
      },
      "source": [
        "p_recall_f(y_test, predsc2, average='macro')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5760576474072049, 0.5717489475477215, 0.5736857827882093, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTxb1uLkwnuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43b06fbb-1add-41f7-a432-f5c30364a7c5"
      },
      "source": [
        "p_recall_f(y_test, predsc2, average='weighted')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5720549902693824, 0.5708935259497058, 0.571245124694644, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C2Oy-UdUNIA",
        "colab_type": "text"
      },
      "source": [
        "MODEL SUMMARY FOR CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DnlybbpwvAO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "06342d83-6519-4439-bb99-4f03ceb76cf4"
      },
      "source": [
        "CNN2.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 400)         8000000   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, None, 400)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, None, 300)         360300    \n",
            "_________________________________________________________________\n",
            "lambda_2 (Lambda)            (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 300)               90300     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 903       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 8,451,503\n",
            "Trainable params: 8,451,503\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4fN7J0IUQqF",
        "colab_type": "text"
      },
      "source": [
        "LSTM MODEL Defination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kPrIAWjvepI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6f6120b9-bd61-450e-817d-586313770a6d"
      },
      "source": [
        "from keras import optimizers\n",
        "def max_1d(X):\n",
        "    return K.max(X, axis=1)\n",
        "\n",
        "\n",
        "nb_filter = 300\n",
        "filter_length = 3\n",
        "hidden_dims = 300 # 250\n",
        "nb_epoch = 2\n",
        "\n",
        "\n",
        "LSTM1 = Sequential()\n",
        "LSTM1.add(Embedding(max_features, 400, dropout=0.2))\n",
        "LSTM1.add(LSTM(30, activation='tanh' ))\n",
        "\n",
        "LSTM1.add(Dense(hidden_dims))\n",
        "LSTM1.add(Dropout(0.2))\n",
        "LSTM1.add(Activation('relu'))\n",
        "LSTM1.add(Dense(num_classes))\n",
        "LSTM1.add(Activation('sigmoid'))\n",
        "adam = optimizers.Adam(lr=0.001, decay=1e-6)\n",
        "LSTM1.compile(loss='categorical_crossentropy',\n",
        "             optimizer=adam,\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjP-YuleytmN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "1d76629f-f1ae-4b25-ad45-d18b43c11370"
      },
      "source": [
        "LSTM1.fit(X_train_1, Y_train, epochs = 1)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "15131/15131 [==============================] - 221s 15ms/step - loss: 0.9014 - acc: 0.5545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda72c84ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJQGb7SPH-Im",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e80e4aa-6042-4521-c68e-6472c8c98fa4"
      },
      "source": [
        "predls1 = LSTM1.predict_classes(X_test_1, verbose=0)\n",
        "np.sum(predls1==y_test)/len(y_test)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5698234349919743"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj6x8L7nUViu",
        "colab_type": "text"
      },
      "source": [
        "Accuracy for 1 Epoch trained LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGrcEtygIFOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6581c86-3c47-4334-a97e-23a360b1116b"
      },
      "source": [
        "p_recall_f(y_test, predls1, average='micro')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5698234349919743, 0.5698234349919743, 0.5698234349919743, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUonenFTIGMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "387e6924-a1f6-4af0-bc4c-aaa56cc215bd"
      },
      "source": [
        "p_recall_f(y_test, predls1, average='macro')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5983334917466654, 0.55528980704776, 0.5646979083528513, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHRdzpofIG4L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e598315-3639-40b9-aee8-4b991585cf4e"
      },
      "source": [
        "p_recall_f(y_test, predls1, average='weighted')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5886240195091994, 0.5698234349919743, 0.5673104291822505, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zLMrCeAUZz9",
        "colab_type": "text"
      },
      "source": [
        "LSTM MODEL SUMMARY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xczwz_soIR7Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "fb5b8f0b-eb64-4116-a153-7d140f9e755d"
      },
      "source": [
        "LSTM1.summary()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, None, 400)         8000000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 30)                51720     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 300)               9300      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 903       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 8,061,923\n",
            "Trainable params: 8,061,923\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7eb1733d-68d6-4886-ae08-742d17c73769",
        "id": "0VSQvY480XAi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from keras import optimizers\n",
        "def max_1d(X):\n",
        "    return K.max(X, axis=1)\n",
        "\n",
        "\n",
        "nb_filter = 300\n",
        "filter_length = 3\n",
        "hidden_dims = 300 # 250\n",
        "nb_epoch = 2\n",
        "\n",
        "\n",
        "LSTM2 = Sequential()\n",
        "LSTM2.add(Embedding(max_features, 400, dropout=0.2))\n",
        "LSTM2.add(LSTM(30, activation='tanh' ))\n",
        "\n",
        "LSTM2.add(Dense(hidden_dims))\n",
        "LSTM2.add(Dropout(0.2))\n",
        "LSTM2.add(Activation('relu'))\n",
        "LSTM2.add(Dense(num_classes))\n",
        "LSTM2.add(Activation('sigmoid'))\n",
        "adam = optimizers.Adam(lr=0.001, decay=1e-6)\n",
        "LSTM2.compile(loss='categorical_crossentropy',\n",
        "             optimizer=adam,\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCimtiE5z3AJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "origLSTM = deepcopy(LSTM2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4xh56Q70liR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "50deccf1-f7f8-4c66-9cbb-f50d226ad921"
      },
      "source": [
        "LSTM2.fit(X_train_1, Y_train, epochs = 3)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "15131/15131 [==============================] - 219s 15ms/step - loss: 0.9107 - acc: 0.5444\n",
            "Epoch 2/3\n",
            "15131/15131 [==============================] - 217s 14ms/step - loss: 0.6730 - acc: 0.7101\n",
            "Epoch 3/3\n",
            "15131/15131 [==============================] - 211s 14ms/step - loss: 0.4315 - acc: 0.8352\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda71aeec88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpA0zrkvy6uC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7b9494b-4a6a-4522-fc7d-526980871289"
      },
      "source": [
        "predls2 = LSTM2.predict_classes(X_test_1, verbose=0)\n",
        "np.sum(predls2==y_test)/len(y_test)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5377207062600321"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0PUwWUO0t-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11ad5940-9fe7-47f8-da77-4b6a2fbac8ba"
      },
      "source": [
        "p_recall_f(y_test, predls2, average='micro')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5377207062600321, 0.5377207062600321, 0.5377207062600321, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww-zUUL9HvVf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "acd5062a-64eb-484d-8e30-e195db8db84c"
      },
      "source": [
        "p_recall_f(y_test, predls2, average='macro')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5394084152440005, 0.5469916876149264, 0.5415937362161314, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5HdkrmiH1sj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "730b8512-48bc-4b4a-bc0c-a26688bf88f0"
      },
      "source": [
        "p_recall_f(y_test, predls2, average='weighted')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5368771451793373, 0.5377207062600321, 0.5358117538174243, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    }
  ]
}